{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span style=\"color:blue\"> Projeto 01 - Concessão de cartões de crédito </span>\n<span style=\"color:blue\"> Este notebook é semelhante ao visto em vídeo, mas contém células azuis como esta, que trazem instruções para a sua atividade.</span>\n\n<span style=\"color:blue\">Após realizar as tarefas indicadas, você vai fazer o upload do seu arquivo no GitHub e enviar o link para a EBAC, ou alternativamente, fazer o upload do arquivo na plataforma da EBAC. Recomendamos o github, pois assim você já vai montando o seu portfólio.</span>","metadata":{"id":"AjXudDHfOnu5"}},{"cell_type":"markdown","source":"## Etapa 1 CRISP - DM: Entendimento do negócio\n\nComo primeira etapa do CRISP-DM, vamos entender do que se trata o negócio, e quais os objetivos. \n\nEste é um problema de concessão de cartões de crédito, publicado no [Kaggle](https://www.kaggle.com/), uma plataforma que promove desafios de ciência de dados, oferecendo prêmios em dinheiro para os melhores colocados. O link original está [aqui](https://www.kaggle.com/rikdifos/credit-card-approval-prediction).  \n  \nEssa é uma base de proponentes de cartão de crédito, nosso objetivo é construir um modelo preditivo para identificar o risco de inadimplência (tipicamente definida pela ocorrência de um atraso maior ou igual a 90 em um horizonte de 12 meses) através de variáveis que podem ser observadas na data da avaliação do crédito (tipicamente quando o cliente solicita o cartão).\n\nAtividades do CRISP-DM:\n\n- Objetivos do negócio\nNote que o objetivo aqui é que o modelo sirva o mutuário (o cliente) para que avalie suas próprias decisões, e não a instituição de crédito.\n- Objetivos da modelagem\nO objetivo está bem definido: desenvolver o melhor modelo preditivo de modo a auxiliar o mutuário a tomar suas próprias decisões referentes a crédito.\n  \nNessa etapa também se avalia a situação da empresa/segmento/assunto de modo a se entender o tamanho do público, relevância, problemas presentes e todos os detalhes do processo gerador do fenômeno em questão, e portanto dos dados.\n\nTambém é nessa etapa que se constrói um planejamento do projeto.","metadata":{"id":"rRLmFL8pOnu9"}},{"cell_type":"markdown","source":"## Etapa 2 Crisp-DM: Entendimento dos dados\nA segunda etapa é o entendimento dos dados. Foram fornecidas 15 variáveis mais a variável resposta (em negrito na tabela). O significado de cada uma dessas variáveis se encontra na tabela.\n\n#### Dicionário de dados\n\nOs dados estão dispostos em uma tabela com uma linha para cada cliente, e uma coluna para cada variável armazenando as características desses clientes. Colocamos uma cópia o dicionário de dados (explicação dessas variáveis) abaixo neste notebook:\n\n| Variable Name            | Description                                         | Tipo  |\n| ------------------------ |:---------------------------------------------------:| -----:|\n| sexo| M = 'Masculino'; F = 'Feminino' |M/F|\n| posse_de_veiculo| Y = 'possui'; N = 'não possui' |Y/N|\n| posse_de_imovel| Y = 'possui'; N = 'não possui' |Y/N|\n| qtd_filhos| Quantidade de filhos |inteiro|\n| tipo_renda|Tipo de renda (ex: assaliariado, autônomo etc) | texto |\n| educacao| Nível de educação (ex: secundário, superior etc) |texto|\n| estado_civil | Estado civil (ex: solteiro, casado etc)| texto |\n| tipo_residencia | tipo de residência (ex: casa/apartamento, com os pais etc) | texto |\n| idade | idade em anos |inteiro|\n| tempo de emprego | tempo de emprego em anos |inteiro|\n| possui_celular | Indica se possui celular (1 = sim, 0 = não) |binária|\n| possui_fone_comercial | Indica se possui telefone comercial (1 = sim, 0 = não) |binária|\n| possui_fone | Indica se possui telefone (1 = sim, 0 = não) |binária|\n| possui_email | Indica se possui e-mail (1 = sim, 0 = não) |binária|\n| qt_pessoas_residencia | quantidade de pessoas na residência |inteiro|\n| **mau** | indicadora de mau pagador (True = mau, False = bom) |binária|\n\n\n\n","metadata":{"id":"M4dcBg6lOnu_"}},{"cell_type":"markdown","source":"#### Carregando os pacotes\nÉ considerado uma boa prática carregar os pacotes que serão utilizados como a primeira coisa do programa.","metadata":{"id":"q5fWHFifOnvB"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"id":"wxDts4aDOnvC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Carregando os dados\nO comando pd.read_csv é um comando da biblioteca pandas (pd.) e carrega os dados do arquivo csv indicado para um objeto *dataframe* do pandas.","metadata":{"id":"q3AMDY6rOnvE"}},{"cell_type":"code","source":"# Observe que demo01.csv está na mesma pasta que este notebook\n# do contrário, seria necessário indicar a pasta no nome do arquivo\ndf = pd.read_csv('demo01.csv')\nprint (\"Número de linhas e colunas da tabela: {}\".format(df.shape))\n\ndf.head()","metadata":{"id":"WiipXAyNOnvF","outputId":"8ce5d637-8738-484c-8119-66e15cccf3b8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Entendimento dos dados - Univariada\nNesta etapa tipicamente avaliamos a distribuição de todas as variáveis. Nesta demonstração vamos ver a variável resposta e dois exemplos de univariada apenas. Mas sinta-se à vontade para tentar observar outras variáveis.","metadata":{"id":"pu_Vkxg4OnvG"}},{"cell_type":"code","source":"print(df['mau'].value_counts())\nprint(\"\\nTaxa de inadimplentes:\")\nprint(df['mau'].mean())","metadata":{"id":"8yta7GryOnvG","outputId":"197543c4-6337-4aa3-9b40-e3d39cf4676f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'mau'\ngrafico_barras = df[var].value_counts().plot.bar()","metadata":{"id":"ZzP4KURCOnvI","outputId":"2f2cd59a-eb0d-47cd-df22-4ea40b5e88cb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:blue\">Tarefa 01 - gráfico de barras</span>\n<span style=\"color:blue\"> Com base no código da célula anterior, construa um gráfico de barras para pelo menos duas outras variáveis. \n**Dica:** Não tente usar as variáveis ```tempo_emprego``` e ```idade``` pois o gráfico de barras dessa forma como construímos não é adequado para elas. </span>","metadata":{"id":"N60Mju5uOnvJ"}},{"cell_type":"code","source":"def calc_freq_abs(df: pd.DataFrame, col_calc: str, col_ref:str = None, val_ref = None) -> list:\n    aux = []\n    if val_ref == None:\n        aux = df[col_calc].value_counts()\n    else:\n        aux = df[df[col_ref]==val_ref][col_calc].value_counts()\n    return aux\n\ndef calc_freq_rel(df: pd.DataFrame, col_calc: str, col_ref:str = None, val_ref = None) -> list:\n    return calc_freq_abs(df,col_calc,col_ref,val_ref)/df.shape[0]\n\n\ndef break_apart(l: list = [], df: pd.DataFrame = pd.DataFrame(), col: str = None):\n    list_aux = []\n    if not bool(l) and col:\n        l = list(df[col])\n    for i in l:\n        if i not in list_aux:\n            list_aux.append(i)\n    return list_aux\n\ndef df_abs_freq(l:list) -> pd.DataFrame:\n    df1 = pd.DataFrame(data=l.index, columns=['tipo'])\n    df2 = pd.DataFrame(list(l), columns=['freq_abs'])\n    df3 = pd.DataFrame.merge(df1, df2, left_index=True, right_index=True)\n    return df3\n","metadata":{"id":"THsjFHR5OrCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bloco de codigo [6] criando graficos de colunas com valores absolutos para as\n# variaveis categoricas do lista list_cols.\n# Cada variavel ganha 3 graficos, 1º com o total, 2º com os bons pagadores, 3º com os maus pagadores\nx=0\ny=0\ncont=0\nlist_cols = ['tipo_renda', 'educacao', 'estado_civil']\ncol_r = 'mau'\nlx = (None, False, True)\n\naux_lx=[]\ntemp_x =[]\naux_ly = break_apart(df=df, col=list_cols)\n\nfigura, ex = plt.subplots(len(aux_ly),len(lx), figsize=(25, 12))\n\nfor i in aux_ly:\n  for j in lx:\n    temp_lx = calc_freq_abs(df=df,col_calc=i,col_ref='mau',val_ref=j)\n    aux_lx.append(df_abs_freq(temp_lx))\n\n    x= cont%3\n    y= int(np.trunc(cont/3))\n    f = sns.barplot(x='tipo', y='freq_abs', data=aux_lx[cont], ax=ex[y,x])\n    if lx[x]==None:\n      n_x = 'TOTAL'\n    else:\n      n_x = f'Mau Pagador? {lx[x]}'\n    f.set(title=n_x, xlabel='', ylabel='Frequência Absoluta')\n    plt.setp(f.get_xticklabels(), rotation=30)\n    cont += 1\n\nplt.subplots_adjust(bottom=0.01, top=1.5, wspace=1.0, hspace=1.0)\n\nfigura.show()","metadata":{"id":"IvV0K3M4ipDd","outputId":"b91bd060-cc6a-4752-9c69-e1c865736bef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bloco de codigo [7] mostrando a relação de Maus pagadores por valor de cada variavel categorica\n# existente na lista de nome list_cols\n# As relações foram transformadas em pd.DataFrame para serem melhores visualizadas\nlist_rel = []\nfor i in list_cols:\n  df_rel = df_abs_freq(calc_freq_rel(df, i, 'mau', True))\n  list_rel.append(df_rel)\n\nprint(list_cols[0])\nprint(list_rel[0])\nprint()\nprint(list_cols[1])\nprint(list_rel[1])\nprint()\nprint(list_cols[2])\nprint(list_rel[2])\n","metadata":{"id":"g1KDVepNQsfg","outputId":"c1bd3476-c5fd-4a05-82b4-cefab5d29a52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nvar = \"tempo_emprego\"\n\nsns.displot(df, x = var, bins = 50)\nplt.show()","metadata":{"id":"-nB_KJiGOnvK","outputId":"46ba04d1-a75f-43bf-ec4b-e6b6b8623126"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Alterando valores de -1000 pra -2, para visualizar melhor no gráfico\nvar = \"tempo_emprego\"\ndf.loc[df[var]<0,var] = -2","metadata":{"id":"7GNIeYSlOnvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nvar = \"tempo_emprego\"\n\nsns.displot(df, x = var, bins = 50)\nplt.show()","metadata":{"id":"CQ6Gp3nMOnvM","outputId":"4d297950-4273-491d-8d9d-36b9ec4b46da"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:blue\">Tarefa 02 - Histograma </span>\n<span style=\"color:blue\"> Com base no código da célula anterior, construa o histograma da variavel ```dade```.  </span>\n","metadata":{"id":"RdRBhRy6OnvN"}},{"cell_type":"code","source":"# Bloco de codigo [11] construção de 3 graficos historigrama para a variavel quantitativa continua\n# \"idade\", sendo o 1º com todos os valores dessa variavel, ela representa quase uma normal, o 2º\n# nos mostra os Maus Pagadores, a uma predominancia de maus pagadores nos estremos, criando\n# um grafico em forma de \"U\", já o 3º grafico nos dá novamente algo parecido com uma normal \n\nlx = (None, False, True)\nplt.clf()\nvar = \"idade\"\n\nfigura, ax = plt.subplots(3,0, figsize=(25, 12))\nax[0]\nf1 = sns.displot(df, x = var, bins = 50)\nf1.set(title='TODOS', xlabel='idade')\nax[1]\nf2 = sns.displot(df[df['mau']==True], x = var, bins = 50)\nf2.set(title='MAU PAGADOR', xlabel='idade')\nax[2]\nf3 = sns.displot(df[df['mau']==False], x = var, bins = 50)\nf3.set(title='BOM PAGADOR', xlabel='idade')\nplt.show()","metadata":{"id":"r6hEVGyTlXC1","outputId":"481cf746-dac7-4587-9412-728e7594d15a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Entendimento dos dados - Bivariadas\n\nEntender a alteração da inadimplência indicada pela variável resposta (```AtrasoRelevante2anos```) e as variáveis explicativas (demais). Para isto, vamos calcular a taxa de inadimplentes (qtd inadimplentes / total) para diferentes grupos definidos pelas variáveis explicativas.\n","metadata":{"id":"Js5BrZmAOnvO"}},{"cell_type":"code","source":"var = 'idade'\ncat_srs, bins = pd.qcut(df[var], 4, retbins=True)\ng = df.groupby(cat_srs)\nbiv = g['mau'].mean()\n\nax = biv.plot.line()\nax.set_ylabel(\"Proporção de inadimplentes\")\nticks = plt.xticks(range(len(biv.index.values)), biv.index.values, rotation = 90)","metadata":{"id":"Rs8IzeU9OnvP","outputId":"fcdbe802-41a4-408b-e621-4feca2fec0d3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:blue\">Tarefa 03 - Bivariada </span>\n<span style=\"color:blue\"> Com base no código da célula anterior, construa uma análise bivariada para a variável  ```tempo_emprego```.  Em seguida, insira uma célula de markdown e conclua se a variável parece discriminar risco de crédito. </span>\n\n","metadata":{"id":"nX7NOHhzOnvQ"}},{"cell_type":"code","source":"var = \"tempo_emprego\"\ncat_srs, bins = pd.qcut(df[var], 4, retbins=True)\ng = df.groupby(cat_srs)\nbiv = g['mau'].mean()\n\nax = biv.plot.line()\nax.set_ylabel(\"Proporção de inadimplentes\")\nticks = plt.xticks(range(len(biv.index.values)), biv.index.values, rotation = 90)","metadata":{"id":"IW7VWiVVOnvR","outputId":"7de6f235-e171-4d44-da3d-2d2031a0ba1a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1. ANALISE**\n\n1.1. VARIAVEIS CATEGORICAS\n\n  Foi contruido 3 graficos de colunas para cada uma das seguintes variaveis categoricas: tipo_renda, educacao, estado_civil. O 1º Grafico, representa o total de individos de cada categoria, o 2º representa quanto desse total responde a seguinte pergunta, \"Mau Pagador?\", como False, ja o 3º representa o quanto desse total responde a seguinte pergunta, \"Mau Pagador?\", como True.\n\n  Verificando os graficos e comparando, não existe nenhum padrão de relacionamento que seja muito forte.\n\n  Por tanto foi contruido em sequncia pd.DataFrames que possuem a frequencia relatica, dessas variaveis com o estatos de \"Mau Pagador\". Essa tabela nos permitiu chegar a algumas conclusões:\n  \n  1.1.1. **Tipo de Renda** \n  \n  Analizando esse item notamos que os maiores devedores ganham a vida como \"Working\", tendo uma inadiplencia de 1,13% o dobro da segunda modalidade de renda, \"Commercial associate\" com um grau de individamento em 0,59%.\n\n  1.1.2. **Educacao**\n\n  O grande devedor nesse caso são aqueles q possuem formação academica como: 0  \"Secondary / secondary special\", tendo um grão de individamento na ordem de 1,46% contra: \"Higher education\" com 0,69%, \"Incomplete higher\"  0,15% e \"Lower secondary\" com 0,04%\n\n  1.1.3. **Estado Civil**\n\n  Verificando o estado civil, percebe-se que os mais indicidados são os que estão casados, veja: \"Married\" tem 1,45%, todos os outros tem valores abaixo de 0,4%.\n\n1.2 VARIAVEIS QUANTITATIVAS CONTINUAS\n\n1.2.1. **IDADE**\n\nForam criados 3 historigramas, sendo o 1º com o valor total das idades, esse possui uma forma proxima a Normal, o 2º com as idades apenas dos \"Maus Pagadores\", esse ja possui uma forma mais proxima a de um \"U\", e por fim o grafico do \"Bons Pagadores\" que novamente se aproxima de uma Normal. \nTanto o historigrama quando o poligono de frequncia, nos permitem entender que a faixa com maior inadiplencia entá entre os mais jovens, essa inadiplencia cai rapidamente, tendo seu menor ponto por volta dos 35 anos, depois volta a crescer com um angulo de inclinação bem mais suave.\n\n1.2.2. ** Tempo de Emprego **\n\nAtraves do grafico de poligono de frequencia, exibe um auto individamente entre os desempregados e os com pouco tempo de emprego, tendo seu apce em 1,2 anos de trabalho e depois caindo com um coeficiente linear bem elevado até os 4,7 anos de trabalho, depois continua caindo mas de forma mais amena.\n\n**2. CONCLUSÃO**\n\nRecomendamos realizar os emprestimos para individuos adultos com cerca de 3 decadas de vida, e com o maior tempo de emprego possivel, as variaveis categoricas tem uma variação entre elas pouco relevantes para uma analise grafica, assim em primeira analise podemos descartalas como metricas de decisão.\n","metadata":{"id":"oEZhCh7tOnvR"}},{"cell_type":"markdown","source":"## Etapa 3 Crisp-DM: Preparação dos dados\nNessa etapa realizamos tipicamente as seguintes operações com os dados:\n- seleção\nNeste caso, os dados já estão pré-selecionados\n- limpeza\nPrecisaremos identificar e tratar dados faltantes\n- construção\nNeste primeiro exercício não faremos construção de novas variáveis\n- integração\nTemos apenas uma fonte de dados, não é necessário agregação\n- formatação\nOs dados já se encontram em formatos úteis\n\nOs dados já estão pré-selecionados, construídos e integrados, mas há dados faltantes que serão eliminados na próxima célula","metadata":{"id":"FViWPj-dOnvR"}},{"cell_type":"code","source":"metadata = pd.DataFrame(df.dtypes, columns = ['tipo'])\n\nmetadata['n_categorias'] = 0\n\nfor var in metadata.index:\n    metadata.loc[var,'n_categorias'] = len(df.groupby([var]).size())\n    \nmetadata","metadata":{"id":"I_gXJgtTOnvR","outputId":"be1ca108-7cfd-4730-d968-2943b7a77ee9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_dummy(df, feature,rank=0):\n    pos = pd.get_dummies(df[feature], prefix=feature)\n    mode = df[feature].value_counts().index[rank]\n    biggest = feature + '_' + str(mode)\n    pos.drop([biggest],axis=1,inplace=True)\n    df.drop([feature],axis=1,inplace=True)\n    df=df.join(pos)\n    return df","metadata":{"id":"e0P3jZlfOnvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for var in metadata[metadata['tipo'] == 'object'].index:\n    df = convert_dummy(df, var)","metadata":{"id":"Bav7XU03OnvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"rDn8e4myOnvU","outputId":"28eba012-36dd-4f18-a02d-024fa9cfce0e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Etapa 4 Crisp-DM: Modelagem\nNessa etapa que realizaremos a construção do modelo. Os passos típicos são:\n- Selecionar a técnica de modelagem\nUtilizaremos a técnica de floresta aleatória (**random forest**), pois é uma técnica bastante versátil e robusta que captura bem padrões complexos nos dados, relativamente fácil de se usar e que costuma produzir excelentes resultados para uma classificação como estas. Vamos ver esse algoritmo em detalhes mais adiante no curso, mas pense nele por enquanto como uma regra complexa baseada nas variáveis explicativas que classifica o indivíduo como inadimplente ou não. Mais adiante no curso vamos extrair mais dessa técnica.\n- Desenho do teste\nAntes de rodar o modelo precisamos construir um desenho do teste que será realizado. Para desenvolver um modelo como este, é considerado uma boa prática dividir a base em duas, uma chamada ```treinamento```, onde o algoritmo 'aprende', e outra chamada ```teste```, onde o algoritmo é avaliado. Essa prática fornece uma métrica de avaliação mais fidedigna do algoritmo, falaremos mais detalhes em lições futuras.\n- Avaliação do modelo\nFaremos a avaliação do nosso modelo através do percentual de acerto, avaliando a classificação do modelo (inadimplente e não inadimplente) e comparando com o estado real armazenado na variável resposta (```AtrasoRelevante2anos```). Esse percentual de acerto é frequentemente chamado de acurácia (**obs:** nunca usar assertividade... a**ss**ertivo não é aquele que a**c**erta, e sim \"*adj.: em que o locutor declara algo, positivo ou negativo, do qual assume inteiramente a validade; declarativo*.\" a**C**ertivo está errado ;)\n#### Dividindo a base em treino e teste\n\n","metadata":{"id":"E8IAjuXfOnvV"}},{"cell_type":"code","source":"# Tirando a v. resposta da base de treinamento\nx = df.drop(\"mau\",axis = 1)\ny = df[\"mau\"]\n\n# Tirando ID da base de treinamento e teste\nx_train, x_test, y_train, y_test = train_test_split(x, y)","metadata":{"id":"utka2HZ4OnvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"id":"QlzzFmZTOnvW","outputId":"24cae2b5-94fb-4c50-bdef-4fdd25d6e6c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rodando o modelo\nA função RandomForestClassifier gera a estrutura da floresta aleatória, e o parâmetro ```n_estimator``` define o número de árvores na floresta. Normalmente a acurácia do modelo tende a aumentar com o número de árvores, pelo menos até um certo limite - e aumenta também o recurso computacional demandado. Você pode alterar esse parâmetro e verificar se a acurácia do seu modelo melhora - não recomendamos valores muito altos. Vá alterando aos poucos e percebendo como o tempo aumenta com os seus recursos. Não é necessário ir muito além de umas 100 árvores.","metadata":{"id":"MAgNr-_POnvW"}},{"cell_type":"code","source":"# Treinar uma Random Forest com 5 árvores\n\nclf = RandomForestClassifier(n_estimators=3)\nclf.fit(x_train,y_train)","metadata":{"id":"OAg3ZWYMOnvW","outputId":"5864a986-7ca4-44ea-ad8d-52d5ed24788f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculando a acuracia\n\ny_pred = clf.predict(x_test)\nacc = metrics.accuracy_score(y_test, y_pred)\nprint('Acurácia: {0:.2f}%'.format(acc*100))","metadata":{"id":"xx1i4N8FOnvX","outputId":"20543494-398c-4df3-b971-bc2666fa8cb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matriz de confusão\n\ntab = pd.crosstab(index = y_pred, columns = y_test)\nprint(tab[1][0]/(tab[1][0] + tab[0][0]))\nprint(tab[1][1]/(tab[1][1] + tab[0][1]))\ntab","metadata":{"id":"euBEt2VUOnvY","outputId":"442ddf0a-8a2b-443b-d384-9386e09737f0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:blue\">Tarefa 04 - Bivariada </span>\n<span style=\"color:blue\"> Para essa tarefa, crie três células extras, copie nelas o código das três células anteriores (na mesma ordem) e altere o parâmetro ```n_estimators=``` da função ```RandomForestClassifier``` e insira uma quantidade maior que 3 nesse parâmetro. Rode as três células anteriores para calcular a acurácia do modelo e veja se você consegue uma acurácia melhor. </span>","metadata":{"id":"3J5kU7UhOnvY"}},{"cell_type":"code","source":"# Treinar uma Random Forest com 5 árvores\nclf = RandomForestClassifier(n_estimators=80)\nclf.fit(x_train,y_train)\n\n# Calculando a acuracia\ny_pred = clf.predict(x_test)\nacc = metrics.accuracy_score(y_test, y_pred)\nprint('Acurácia: {0:.2f}%'.format(acc*100))\nprint()\n\n# Matriz de confusão\ntab = pd.crosstab(index = y_pred, columns = y_test)\nprint(tab[1][0]/(tab[1][0] + tab[0][0]))\nprint(tab[1][1]/(tab[1][1] + tab[0][1]))\ntab","metadata":{"id":"MHTUk-qQkvDG","outputId":"f4ef785d-b826-4735-976b-a286f3384276"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treinar uma Random Forest com 5 árvores\n\nclf = RandomForestClassifier(n_estimators=10)\nclf.fit(x_train,y_train)","metadata":{"id":"0zyRoMhPOnva","outputId":"6ad77709-041d-4de7-8f95-27c6442e47d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculando a acuracia\n\ny_pred = clf.predict(x_test)\nacc = metrics.accuracy_score(y_test, y_pred)\nprint('Acurácia: {0:.2f}%'.format(acc*100))","metadata":{"id":"4vf14BUyOnva","outputId":"9c9133d1-e64e-4b3e-8ff2-13f74fd3a8d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matriz de confusão\n\ntab = pd.crosstab(index = y_pred, columns = y_test)\nprint(tab[1][0]/(tab[1][0] + tab[0][0]))\nprint(tab[1][1]/(tab[1][1] + tab[0][1]))\ntab","metadata":{"id":"w7-nL6oDOnvb","outputId":"1037b5e5-9a00-4432-ddfc-040465312d68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Etapa 5 Crisp-DM: Avaliação dos resultados\nA etapa final do CRISP. Neste casp, a nossa avaliação termina com a acurácia. Mas em problemas futuros aprofundaremos mais - a ideia seria avaliar o impacto do uso do modelo no negócio, ou seja, o quanto o resultado financeiro melhora em detrimento da utilização do modelo.\n\nComo um exemplo simples, considere que um cliente bom pagador deixa (em média) 5 '*dinheiros*' de lucro, e um mau pagador deixa (em média) 100 '*dinheiros*' de prejuízo.\n\nde acordo com a matriz de confusão:\n\n| Decisão   | lucro dos bons    | lucro dos maus | total  |\n| --------- |:-----------------:|:--------------:| ------:|\n| Aprovador | 4042 x 5          | 72 x (-100)    | 13.010 |\n| Reprovar  |  27 x 5           | 22 x (-100)    | -2.065 |\n\nEstariamos evitando, portanto, um prejuízo de -2.145 '*dinheiros*' - o que na prática significa um aumento no lucro.\n","metadata":{"id":"ZErPxse6Onvb"}},{"cell_type":"markdown","source":"## Etapa 6 Crisp-DM: Implantação\nNessa etapa colocamos em uso o modelo desenvolvido, normalmente implementando o modelo desenvolvido em um motor de crédito que toma as decisões com algum nível de automação - tipicamente aprovando automaticamente clientes muito bons, negando automaticamente clientes muito ruins, e enviando os intermediários para análise manual.","metadata":{"id":"gLxiaEfNOnvc"}}]}